## Анализ защищенности систем искусственного интеллекта. 

#### Практические и лабораторные работы по дисциплине: Анализ защищенности систем искусственного интеллекта.

#### Подготовил студент группы ББМО-02-23 Палаткин Андрей Андреевич

>######  Связь: [Telegram](https://t.me/aapalatkin), [VK](https://vk.com/netburst68), andreypalatkin@duck.com    
#
##### [Практическая работа 1: Установка окружения и настройка фреймворков для анализа защищенности ИИ](ПР1)
##### [Практическая работа 2: Исследование атак на модели ИИ. Fast Gradient Sign Method (FGSM)](ПР2)
##### [Практическая работа 3: Атака Carlini-Wagner (CW) на модели ИИ](ПР3)
##### *<ins>(in progress)</ins>* Практика 4: Атака DeepFool на модели ИИ  
##### [Практическая работа 5: Атака с ограниченной памятью (PGD - Projected Gradient Descent)](ПР5)
##### [Практическая работа 6: Атака по переносу (Transfer Attack) на модели ИИ](ПР6)
##### [Практическая работа 7: Создание и использование генеративных противоречивых примеров (GAN-based Adversarial Examples)](ПР7)
##### *<ins>(in progress)</ins>* Практика 8: Методы защиты от атак на модели ИИ  
#
##### [Лабораторная работа 1](ЛР1)
##### [Лабораторная работа 2](ЛР2)
##### [Лабораторная работа 3](ЛР3)
